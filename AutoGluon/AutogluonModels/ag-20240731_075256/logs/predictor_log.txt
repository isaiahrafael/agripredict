Warning: path already exists! This predictor may overwrite an existing predictor! path="autogloun-daily"
Beginning AutoGluon training... Time limit = 1200s
AutoGluon will save models to 'autogloun-daily'
=================== System Info ===================
AutoGluon Version:  1.1.1
Python Version:     3.11.7
Operating System:   Darwin
Platform Machine:   x86_64
Platform Version:   Darwin Kernel Version 23.5.0: Wed May  1 20:09:52 PDT 2024; root:xnu-10063.121.3~5/RELEASE_X86_64
CPU Count:          8
GPU Count:          0
Memory Avail:       17.83 GB / 32.00 GB (55.7%)
Disk Space Avail:   838.98 GB / 931.55 GB (90.1%)
===================================================
Setting presets to: medium_quality

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'freq': 'D',
 'hyperparameters': 'light',
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 30,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 1200,
 'verbosity': 2}

train_data with frequency 'None' has been resampled to frequency 'D'.
Provided train_data has 5798 rows (NaN fraction=27.0%), 197 time series. Median time series length is 30 (min=25, max=31). 
	Removing 197 short time series from train_data. Only series with length >= 61 will be used for training.
	After filtering, train_data has 0 rows, 0 time series. Median time series length is nan (min=nan, max=nan). 
Warning: path already exists! This predictor may overwrite an existing predictor! path="autogloun-daily"
Beginning AutoGluon training... Time limit = 1200s
AutoGluon will save models to 'autogloun-daily'
=================== System Info ===================
AutoGluon Version:  1.1.1
Python Version:     3.11.7
Operating System:   Darwin
Platform Machine:   x86_64
Platform Version:   Darwin Kernel Version 23.5.0: Wed May  1 20:09:52 PDT 2024; root:xnu-10063.121.3~5/RELEASE_X86_64
CPU Count:          8
GPU Count:          0
Memory Avail:       17.78 GB / 32.00 GB (55.6%)
Disk Space Avail:   838.98 GB / 931.55 GB (90.1%)
===================================================
Setting presets to: medium_quality

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'freq': 'D',
 'hyperparameters': 'light',
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 25,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 1200,
 'verbosity': 2}

train_data with frequency 'None' has been resampled to frequency 'D'.
Provided train_data has 5798 rows (NaN fraction=27.0%), 197 time series. Median time series length is 30 (min=25, max=31). 
	Removing 197 short time series from train_data. Only series with length >= 51 will be used for training.
	After filtering, train_data has 0 rows, 0 time series. Median time series length is nan (min=nan, max=nan). 
Warning: path already exists! This predictor may overwrite an existing predictor! path="autogloun-daily"
Beginning AutoGluon training... Time limit = 1200s
AutoGluon will save models to 'autogloun-daily'
=================== System Info ===================
AutoGluon Version:  1.1.1
Python Version:     3.11.7
Operating System:   Darwin
Platform Machine:   x86_64
Platform Version:   Darwin Kernel Version 23.5.0: Wed May  1 20:09:52 PDT 2024; root:xnu-10063.121.3~5/RELEASE_X86_64
CPU Count:          8
GPU Count:          0
Memory Avail:       17.76 GB / 32.00 GB (55.5%)
Disk Space Avail:   838.98 GB / 931.55 GB (90.1%)
===================================================
Setting presets to: medium_quality

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'freq': 'D',
 'hyperparameters': 'light',
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 20,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 1200,
 'verbosity': 2}

train_data with frequency 'None' has been resampled to frequency 'D'.
Provided train_data has 5798 rows (NaN fraction=27.0%), 197 time series. Median time series length is 30 (min=25, max=31). 
	Removing 197 short time series from train_data. Only series with length >= 41 will be used for training.
	After filtering, train_data has 0 rows, 0 time series. Median time series length is nan (min=nan, max=nan). 
Warning: path already exists! This predictor may overwrite an existing predictor! path="autogloun-daily"
Beginning AutoGluon training... Time limit = 1200s
AutoGluon will save models to 'autogloun-daily'
=================== System Info ===================
AutoGluon Version:  1.1.1
Python Version:     3.11.7
Operating System:   Darwin
Platform Machine:   x86_64
Platform Version:   Darwin Kernel Version 23.5.0: Wed May  1 20:09:52 PDT 2024; root:xnu-10063.121.3~5/RELEASE_X86_64
CPU Count:          8
GPU Count:          0
Memory Avail:       17.75 GB / 32.00 GB (55.5%)
Disk Space Avail:   838.98 GB / 931.55 GB (90.1%)
===================================================
Setting presets to: medium_quality

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'freq': 'D',
 'hyperparameters': 'light',
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 18,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 1200,
 'verbosity': 2}

train_data with frequency 'None' has been resampled to frequency 'D'.
Provided train_data has 5798 rows (NaN fraction=27.0%), 197 time series. Median time series length is 30 (min=25, max=31). 
	Removing 197 short time series from train_data. Only series with length >= 37 will be used for training.
	After filtering, train_data has 0 rows, 0 time series. Median time series length is nan (min=nan, max=nan). 
Warning: path already exists! This predictor may overwrite an existing predictor! path="autogloun-daily"
Beginning AutoGluon training... Time limit = 1200s
AutoGluon will save models to 'autogloun-daily'
=================== System Info ===================
AutoGluon Version:  1.1.1
Python Version:     3.11.7
Operating System:   Darwin
Platform Machine:   x86_64
Platform Version:   Darwin Kernel Version 23.5.0: Wed May  1 20:09:52 PDT 2024; root:xnu-10063.121.3~5/RELEASE_X86_64
CPU Count:          8
GPU Count:          0
Memory Avail:       17.74 GB / 32.00 GB (55.4%)
Disk Space Avail:   838.98 GB / 931.55 GB (90.1%)
===================================================
Setting presets to: medium_quality

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'freq': 'D',
 'hyperparameters': 'light',
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 17,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 1200,
 'verbosity': 2}

train_data with frequency 'None' has been resampled to frequency 'D'.
Provided train_data has 5798 rows (NaN fraction=27.0%), 197 time series. Median time series length is 30 (min=25, max=31). 
	Removing 197 short time series from train_data. Only series with length >= 35 will be used for training.
	After filtering, train_data has 0 rows, 0 time series. Median time series length is nan (min=nan, max=nan). 
Warning: path already exists! This predictor may overwrite an existing predictor! path="autogloun-daily"
Beginning AutoGluon training... Time limit = 1200s
AutoGluon will save models to 'autogloun-daily'
=================== System Info ===================
AutoGluon Version:  1.1.1
Python Version:     3.11.7
Operating System:   Darwin
Platform Machine:   x86_64
Platform Version:   Darwin Kernel Version 23.5.0: Wed May  1 20:09:52 PDT 2024; root:xnu-10063.121.3~5/RELEASE_X86_64
CPU Count:          8
GPU Count:          0
Memory Avail:       17.74 GB / 32.00 GB (55.4%)
Disk Space Avail:   838.98 GB / 931.55 GB (90.1%)
===================================================
Setting presets to: medium_quality

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'freq': 'D',
 'hyperparameters': 'light',
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 16,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 1200,
 'verbosity': 2}

train_data with frequency 'None' has been resampled to frequency 'D'.
Provided train_data has 5798 rows (NaN fraction=27.0%), 197 time series. Median time series length is 30 (min=25, max=31). 
	Removing 197 short time series from train_data. Only series with length >= 33 will be used for training.
	After filtering, train_data has 0 rows, 0 time series. Median time series length is nan (min=nan, max=nan). 
Warning: path already exists! This predictor may overwrite an existing predictor! path="autogloun-daily"
Beginning AutoGluon training... Time limit = 1200s
AutoGluon will save models to 'autogloun-daily'
=================== System Info ===================
AutoGluon Version:  1.1.1
Python Version:     3.11.7
Operating System:   Darwin
Platform Machine:   x86_64
Platform Version:   Darwin Kernel Version 23.5.0: Wed May  1 20:09:52 PDT 2024; root:xnu-10063.121.3~5/RELEASE_X86_64
CPU Count:          8
GPU Count:          0
Memory Avail:       17.72 GB / 32.00 GB (55.4%)
Disk Space Avail:   838.98 GB / 931.55 GB (90.1%)
===================================================
Setting presets to: medium_quality

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'freq': 'D',
 'hyperparameters': 'light',
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 15,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 1200,
 'verbosity': 2}

train_data with frequency 'None' has been resampled to frequency 'D'.
Provided train_data has 5798 rows (NaN fraction=27.0%), 197 time series. Median time series length is 30 (min=25, max=31). 
	Removing 154 short time series from train_data. Only series with length >= 31 will be used for training.
	After filtering, train_data has 1333 rows (NaN fraction=26.5%), 43 time series. Median time series length is 31 (min=31, max=31). 

Provided data contains following columns:
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2024-07-31 15:53:51
Models that will be trained: ['Naive', 'SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Theta', 'TemporalFusionTransformer']
Training timeseries model Naive. Training for up to 149.1s of the 1192.5s of remaining time.
	-1.3230       = Validation score (-MASE)
	0.02    s     = Training runtime
	2.90    s     = Validation (prediction) runtime
Training timeseries model SeasonalNaive. Training for up to 169.9s of the 1189.6s of remaining time.
	-1.4628       = Validation score (-MASE)
	0.02    s     = Training runtime
	0.06    s     = Validation (prediction) runtime
Training timeseries model RecursiveTabular. Training for up to 198.2s of the 1189.5s of remaining time.
	Time series in the dataset are too short for chosen differences [7]. Setting differences to [1].
	Warning: Exception caused LightGBM to fail during training (ImportError)... Skipping this model.
		`import lightgbm` failed. If you are using Mac OSX, Please try 'brew install libomp'. Detailed info: dlopen(/opt/anaconda3/lib/python3.11/site-packages/lightgbm/lib/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib
  Referenced from: <C3EB28DD-60B6-3334-AFA2-72BBBF9DBAEF> /opt/anaconda3/lib/python3.11/site-packages/lightgbm/lib/lib_lightgbm.so
  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file, not in dyld cache)
	Warning: Exception caused RecursiveTabular to fail during training... Skipping this model.
	Trainer has no fit models that can infer.
Training timeseries model DirectTabular. Training for up to 237.0s of the 1184.9s of remaining time.
	Warning: Exception caused LightGBM to fail during training (ImportError)... Skipping this model.
		`import lightgbm` failed. If you are using Mac OSX, Please try 'brew install libomp'. Detailed info: dlopen(/opt/anaconda3/lib/python3.11/site-packages/lightgbm/lib/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib
  Referenced from: <C3EB28DD-60B6-3334-AFA2-72BBBF9DBAEF> /opt/anaconda3/lib/python3.11/site-packages/lightgbm/lib/lib_lightgbm.so
  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file, not in dyld cache)
	Warning: Exception caused DirectTabular to fail during training... Skipping this model.
	Trainer has no fit models that can infer.
Training timeseries model ETS. Training for up to 296.2s of the 1184.6s of remaining time.
	-1.4692       = Validation score (-MASE)
	0.05    s     = Training runtime
	29.64   s     = Validation (prediction) runtime
Training timeseries model Theta. Training for up to 385.0s of the 1154.9s of remaining time.
	-1.4350       = Validation score (-MASE)
	0.05    s     = Training runtime
	11.29   s     = Validation (prediction) runtime
Training timeseries model TemporalFusionTransformer. Training for up to 571.8s of the 1143.6s of remaining time.
	-1.8512       = Validation score (-MASE)
	122.77  s     = Training runtime
	0.06    s     = Validation (prediction) runtime
Fitting simple weighted ensemble.
	Ensemble weights: {'Naive': 0.85, 'SeasonalNaive': 0.08, 'TemporalFusionTransformer': 0.06}
	-1.3127       = Validation score (-MASE)
	0.34    s     = Training runtime
	3.02    s     = Validation (prediction) runtime
Training complete. Models trained: ['Naive', 'SeasonalNaive', 'ETS', 'Theta', 'TemporalFusionTransformer', 'WeightedEnsemble']
Total runtime: 178.79 s
Best model: WeightedEnsemble
Best model score: -1.3127
data with frequency 'None' has been resampled to frequency 'D'.
Model not specified in predict, will default to the model with the best validation score: WeightedEnsemble
